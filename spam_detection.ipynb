{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['email', 'label'], dtype='object')\n",
      "                                               email  label\n",
      "0   date wed NUMBER aug NUMBER NUMBER NUMBER NUMB...      0\n",
      "1  martin a posted tassos papadopoulos the greek ...      0\n",
      "2  man threatens explosion in moscow thursday aug...      0\n",
      "3  klez the virus that won t die already the most...      0\n",
      "4   in adding cream to spaghetti carbonara which ...      0\n"
     ]
    }
   ],
   "source": [
    "email_df = pd.read_csv('files/spam_or_not_spam.csv')\n",
    "print(email_df.columns)\n",
    "print(email_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clean_data(text):\n",
    "    no_punctuation = [char for char in text if char not in string.punctuation]\n",
    "    no_punctuation = ''.join(no_punctuation)\n",
    "\n",
    "    result = [word for word in no_punctuation.split() if word.lower() not in stopwords.words('english')]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "email_df.drop_duplicates(inplace=True)\n",
    "email_df.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 7639)\t1\n",
      "  (0, 31831)\t1\n",
      "  (0, 0)\t42\n",
      "  (0, 3018)\t1\n",
      "  (0, 5701)\t1\n",
      "  (0, 12162)\t1\n",
      "  (0, 7452)\t1\n",
      "  (0, 7640)\t1\n",
      "  (0, 235)\t1\n",
      "  (0, 7852)\t2\n",
      "  (0, 6204)\t2\n",
      "  (0, 18436)\t1\n",
      "  (0, 14254)\t1\n",
      "  (0, 29344)\t1\n",
      "  (0, 31293)\t1\n",
      "  (0, 24560)\t1\n",
      "  (0, 10203)\t2\n",
      "  (0, 24494)\t1\n",
      "  (0, 17141)\t1\n",
      "  (0, 10380)\t1\n",
      "  (0, 29254)\t1\n",
      "  (0, 32162)\t1\n",
      "  (0, 10839)\t1\n",
      "  (0, 7757)\t1\n",
      "  (0, 17395)\t1\n",
      "  :\t:\n",
      "  (2871, 33314)\t1\n",
      "  (2871, 33187)\t2\n",
      "  (2871, 33235)\t1\n",
      "  (2871, 33315)\t1\n",
      "  (2871, 33341)\t1\n",
      "  (2871, 33175)\t1\n",
      "  (2871, 33294)\t1\n",
      "  (2871, 19390)\t1\n",
      "  (2871, 13067)\t2\n",
      "  (2871, 33368)\t2\n",
      "  (2871, 33430)\t2\n",
      "  (2871, 33329)\t1\n",
      "  (2871, 33228)\t1\n",
      "  (2871, 33258)\t1\n",
      "  (2871, 33229)\t1\n",
      "  (2871, 1049)\t1\n",
      "  (2871, 32427)\t1\n",
      "  (2871, 33247)\t1\n",
      "  (2871, 33275)\t1\n",
      "  (2871, 33237)\t1\n",
      "  (2871, 33286)\t1\n",
      "  (2871, 23610)\t1\n",
      "  (2871, 17683)\t1\n",
      "  (2871, 32655)\t1\n",
      "  (2871, 33330)\t1\n"
     ]
    }
   ],
   "source": [
    "emails = email_df['email']\n",
    "vectorizer = CountVectorizer(analyzer=get_clean_data)\n",
    "vectored_emails = vectorizer.fit_transform(emails)\n",
    "print(vectored_emails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "debug\n"
     ]
    }
   ],
   "source": [
    "vocabulary = vectorizer.get_feature_names_out()\n",
    "word_at_index_7639 = vocabulary[7757]\n",
    "print(word_at_index_7639)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_test,y_train,y_test = train_test_split(vectored_emails,email_df['label'],train_size=0.80,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 1 0 1 0 0 0 1 0 1 1 0 0 1\n",
      " 1 1 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 1 0 0 1\n",
      " 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 0 1 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 1 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1\n",
      " 0 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 1 1 0 1 1 0 0 1 0 0 0\n",
      " 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 0 1 0 1 0 1 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1]\n"
     ]
    }
   ],
   "source": [
    "classifier = MultinomialNB()\n",
    "classifier.fit(x_train,y_train)\n",
    "prediction = classifier.predict(x_test)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.01217391304347826\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99       489\n",
      "           1       0.96      0.95      0.96        86\n",
      "\n",
      "    accuracy                           0.99       575\n",
      "   macro avg       0.98      0.97      0.98       575\n",
      "weighted avg       0.99      0.99      0.99       575\n",
      "\n",
      "[[486   3]\n",
      " [  4  82]]\n",
      "0.9878260869565217\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error,classification_report,confusion_matrix,accuracy_score\n",
    "print(mean_squared_error(y_test,prediction))\n",
    "print(classification_report(y_test,prediction))\n",
    "print(confusion_matrix(y_test,prediction))\n",
    "print(\"accuracy : \",accuracy_score(y_test,prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "not a spam\n"
     ]
    }
   ],
   "source": [
    "new_data = ['hey']\n",
    "vectored_new_data = vectorizer.transform(new_data)\n",
    "result = classifier.predict(vectored_new_data)\n",
    "if result[0]==1:\n",
    "    print(\"spam\")\n",
    "else:\n",
    "    print(\"not a spam\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
